{
  "_meta": {
    "version": 1,
    "description": "Demo plan for Students in the Age of Intelligence workshop. Import this via Export/Import section to prefill the app."
  },
  "ikigai.love": "Explaining complex ideas clearly; building simple AI tools that help students learn; running small user tests; sharing what I learn.",
  "ikigai.good": "Technical writing, prompt design, TypeScript/Python basics, rapid prototyping, turning feedback into iterations.",
  "ikigai.pays": "AI education tools, study assistants, internal enablement, workflow automation for teams.",
  "ikigai.needs": "Students and early-career builders who need guidance and leverage; teams that need faster docs and prototypes.",
  "ikigai.statement": "I help students and early-career builders learn faster and show outcomes by creating simple AI tools, clear prompts, and evaluated demos that map to real roles.",
  "analysis.source": "Redacted excerpts from my notes and chats about projects I enjoyed, feedback that energized me, and the kinds of problems I return to. [Names, companies, locations removed].",
  "roles.tracks": "- AI Product (education/enablement)\n- AI/LLM Engineer (RAG + evaluation)\n- Non-AI role using AI: Marketing Ops (automation + analytics)",
  "roles.companies": "Hyperscalers: Microsoft (Azure AI), Google (Vertex AI)\nAI Labs: OpenAI, Anthropic\nTooling: Hugging Face, LangChain, LlamaIndex, W&B\nStartups: Replit, Perplexity, ElevenLabs\nDomain leaders: Duolingo (EdTech), Khan Academy, Coursera (Learning)\nWhy fit: education focus, strong content+AI intersection, clear user outcomes.",
  "plan.30.learn": "- DeepLearning.AI short courses (Prompt Engineering, RAG)\n- LangChain / LlamaIndex docs tour\n- Google Technical Writing (Part 1)",
  "plan.30.build": "- Mini RAG on course notes with a 5-question eval\n- Write a 1-pager (BLUF) on problem + scope + eval",
  "plan.30.publish": "- Post: What I learned building a tiny RAG (with eval results)",
  "plan.30.network": "- 3 messages to EdTech/AI builders with a specific question",
  "plan.60.learn": "- fast.ai intro lectures\n- Evals course (DL.ai)\n- Case study writing examples",
  "plan.60.build": "- Core project: Domain Chat with evals & guardrails\n- Instrument basic quality/speed/cost metrics",
  "plan.60.publish": "- Case study v1 with metrics and a short demo video",
  "plan.60.network": "- 1 coffee chat/week with feedback requests",
  "plan.90.learn": "- Observability and guardrails patterns\n- System Design Primer (selected)",
  "plan.90.build": "- Advanced: add retrieval improvements or a tool call\n- Add a simple monitor + error handling",
  "plan.90.publish": "- 5-min demo talk or livestream",
  "plan.90.network": "- Targeted applications with wedge ideas per company",
  "portfolio.ideas": "- AI Study Buddy (RAG on course notes) — beginner\n- Domain Chat with Evals & Guardrails — intermediate\n- Multi-tool Agent with Planner + Monitor — advanced",
  "portfolio.spec": "Study Buddy (Course Notes)\nOne-liner: Answer study questions from my own notes with citations.\nUser story: As a student, I want quick, trustworthy answers from my notes.\nCore features: upload notes, ask questions, citations, simple eval set.\nDataset/API: local notes, OpenAI/Anthropic model.\nEvaluation approach: 10-question set, accuracy & helpfulness rubric.\nExtensibility idea: spaced repetition deck from answers.",
  "social.headline": "AI Product / LLM Engineer (EdTech) | RAG + Evals | Build → Measure → Learn",
  "social.bio": "I build small, evaluated AI tools for learning and enablement. I share clear write-ups and demos, and iterate with feedback. Focused on education and knowledge workflows.",
  "social.pillars": "- RAG and evaluation\n- Learning workflows\n- Clear prompts and docs\n- Case studies and demos\n- Guardrails and observability",
  "social.calendar": "Week 1: What I learned from a tiny RAG build (+ eval results)\nWeek 1: Prompt patterns I re-use (+ examples)\nWeek 2: Case study outline and first demo\nWeek 2: How I run small user tests\nWeek 3: Guardrails I added and why\nWeek 3: Before/after metrics (quality/speed/cost)\nWeek 4: Lessons learned + roadmap\nWeek 4: Invite for feedback",
  "social.pitch": "Hi, I’m focused on AI for learning. I scope small, evaluated builds and iterate fast. I can show two demos with metrics and the next steps I plan to take.",
  "social.outreach": "Hi [Name], I’m exploring AI for [Company/Team]’s learning/enablement use cases. I built a small RAG demo with evals and a case study (5 min). If useful, I’d love to share the demo and get 1–2 concrete feedback points relevant to [Company]’s priorities. Would a 15-min call next week be reasonable?",
  "agent.spec": "[Problem]\nStudents need reliable, cite-backed answers from their own notes and quick formative feedback.\n[User persona]\nStudents, study groups; TAs building study aids.\n[Capabilities]\nDocument upload, chunking, retrieval with citations; formative feedback rubric; export to spaced repetition.\n[System prompt]\nGround in user docs; cite sources; be concise; state uncertainty.\n[Tools/APIs]\nVector store, LLM, export to CSV.\n[Docs/Retrieval]\nUser-provided notes; keep private locally by default.\n[Guardrails]\nRefuse personal data; highlight uncertainty; max token budget.\n[Test cases]\n10 Q&A with expected answers and rubric.\n[Demo script]\n90 seconds: problem → flow → 2 metrics → call-to-action.\n[Metrics]\nAnswer accuracy, latency, token cost."
}
